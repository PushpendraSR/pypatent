{
 "metadata": {
  "name": "Patent API"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import json\n",
      "import urllib2\n",
      "from BeautifulSoup import BeautifulSoup\n",
      "\n",
      "import cgi\n",
      "import cgitb\n",
      "cgitb.enable()\n",
      "\n",
      "import os\n",
      "from urlparse import urlparse\n",
      "import urllib"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# query = 'abst/(\"behavior\")'\n",
      "query =  '(abst/(\"insect cell\" or \"insect cells\") or ttl/(\"insect cell\" or \"insect cells\") or aclm/(\"insect cell\" or \"insect cells\")) and aclm/codon'\n",
      "#query = 'abst/\"fingerprinting\"'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 178
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "usptoURL = \"http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=0&f=S&l=50&d=PTXT&Query=\"+urllib.quote(query)\n",
      "response = urllib2.urlopen(usptoURL);\n",
      "html = response.read()\n",
      "soup = BeautifulSoup(html)\n",
      "try:\n",
      "    num_hits = int(soup.findAll(\"i\")[1].findAll(\"strong\")[-1].text.replace(',', ''))\n",
      "except IndexError:\n",
      "    num_hits = 0\n",
      "patents = []\n",
      "\n",
      "if num_hits > 0:\n",
      "    while True:\n",
      "        print \"Working on %d/%d\" % (len(patents), num_hits)\n",
      "        table = soup.findAll(\"table\")[1]\n",
      "        \n",
      "        for tr in table.findAll(\"tr\")[1:]:\n",
      "            cells = tr.findAll(\"td\")\n",
      "            patent_number_cell = cells[1].findAll(\"a\")[0]\n",
      "            patent_name_cell = cells[3].findAll(\"a\")[0]\n",
      "            \n",
      "            patent_number =  patent_number_cell.text.replace(',', '')\n",
      "            patent_name = patent_name_cell.text.replace('\\n','').replace(\"     \", \" \")\n",
      "            patent_url = \"http://patft.uspto.gov/\"+patent_number_cell['href']\n",
      "            \n",
      "            patent = {\"number\": patent_number, \n",
      "                        \"name\": patent_name, \n",
      "                        \"url\": patent_url}\n",
      "            patents.append(patent)\n",
      "            \n",
      "        last_center = soup.findAll(\"center\")[-1].findAll(\"table\")[0]\n",
      "        if 'NEXT_LIST' in str(last_center):\n",
      "            print \"Extracting next page\"\n",
      "            available_links = last_center.findAll(\"tr\")[0].findAll(\"td\")[0].findAll(\"a\")\n",
      "            for link in available_links:\n",
      "                if 'NEXT_LIST' in str(link):\n",
      "                    next_page_url = \"http://patft.uspto.gov/\"+link['href']\n",
      "            response = urllib2.urlopen(next_page_url);\n",
      "            html = response.read()\n",
      "            soup = BeautifulSoup(html)\n",
      "        else:\n",
      "            print \"Finished\"\n",
      "            break"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Working on 0/69\n",
        "Extracting next page\n",
        "Working on 50/69"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Finished\n"
       ]
      }
     ],
     "prompt_number": 179
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}